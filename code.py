# -*- coding: utf-8 -*-
"""Blackcoffer Assignment.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hi-zea71Y4nmHJdGYabJ-Oc5VqVE87e8
"""

import requests
from bs4 import BeautifulSoup
from textblob import TextBlob
import nltk
import pandas as pd
import re
from google.colab import files

nltk.download('punkt')
nltk.download('stopwords')

from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize, sent_tokenize

# Function to load positive and negative words from files
def load_word_list(file_path):
    with open(file_path, 'r', encoding='latin-1') as file:
        words = file.read().splitlines()
    return set(words)

# Function to extract article text
def extract_article_text(url):
    try:
        response = requests.get(url)
        response.raise_for_status()
        soup = BeautifulSoup(response.content, 'html.parser')
        title = soup.find('h1').get_text(strip=True)
        article = soup.find('div', class_='td-post-content').get_text(separator=' ', strip=True)
        return title + " " + article
    except Exception as e:
        print(f"Failed to extract article from {url}: {e}")
        return ""

# Function to calculate text analysis metrics
def calculate_metrics(text, positive_words, negative_words):
    # Preprocess text
    stop_words = set(stopwords.words('english'))
    words = word_tokenize(text)
    words = [word for word in words if word.isalpha()]
    filtered_words = [word for word in words if word.lower() not in stop_words]
    filtered_text = ' '.join(filtered_words)

    # Calculate positive and negative scores
    positive_score = sum(1 for word in filtered_words if word.lower() in positive_words)
    negative_score = sum(1 for word in filtered_words if word.lower() in negative_words)

    # Calculate polarity and subjectivity scores using TextBlob
    blob = TextBlob(filtered_text)
    polarity_score = blob.sentiment.polarity
    subjectivity_score = blob.sentiment.subjectivity

    # Calculate average sentence length
    sentences = sent_tokenize(text)
    avg_sentence_length = len(words) / len(sentences) if sentences else 0

    # Calculate percentage of complex words
    def syllable_count(word):
        word = word.lower()
        count = 0
        vowels = "aeiouy"
        if word[0] in vowels:
            count += 1
        for index in range(1, len(word)):
            if word[index] in vowels and word[index - 1] not in vowels:
                count += 1
        if word.endswith("e"):
            count -= 1
        if count == 0:
            count += 1
        return count

    complex_words = [word for word in words if syllable_count(word) > 2]
    percentage_complex_words = len(complex_words) / len(words) * 100 if words else 0

    # Calculate Fog Index
    fog_index = 0.4 * (avg_sentence_length + percentage_complex_words)

    # Calculate average number of words per sentence
    avg_words_per_sentence = len(filtered_words) / len(sentences) if sentences else 0

    # Calculate complex word count
    complex_word_count = len(complex_words)

    # Calculate word count
    word_count = len(filtered_words)

    # Calculate syllables per word
    total_syllables = sum(syllable_count(word) for word in filtered_words)
    syllables_per_word = total_syllables / len(filtered_words) if filtered_words else 0

    # Calculate personal pronouns
    personal_pronouns = len(re.findall(r'\b(I|we|my|ours|us)\b', text, re.I))

    # Calculate average word length
    avg_word_length = sum(len(word) for word in filtered_words) / len(filtered_words) if filtered_words else 0

    return {
        "POSITIVE SCORE": positive_score,
        "NEGATIVE SCORE": negative_score,
        "POLARITY SCORE": polarity_score,
        "SUBJECTIVITY SCORE": subjectivity_score,
        "AVG SENTENCE LENGTH": avg_sentence_length,
        "PERCENTAGE OF COMPLEX WORDS": percentage_complex_words,
        "FOG INDEX": fog_index,
        "AVG NUMBER OF WORDS PER SENTENCE": avg_words_per_sentence,
        "COMPLEX WORD COUNT": complex_word_count,
        "WORD COUNT": word_count,
        "SYLLABLE PER WORD": syllables_per_word,
        "PERSONAL PRONOUNS": personal_pronouns,
        "AVG WORD LENGTH": avg_word_length
    }

# Function to process the input file and generate output file
def process_input_file(input_file, output_file, positive_words_file, negative_words_file, structure_file):
    input_df = pd.read_excel(input_file)
    structure_df = pd.read_excel(structure_file)
    output_data = []

    # Load positive and negative words
    positive_words = load_word_list(positive_words_file)
    negative_words = load_word_list(negative_words_file)

    for index, row in input_df.iterrows():
        url_id = row['URL_ID']
        url = row['URL']
        print(f"Processing {url_id} - {url}")

        article_text = extract_article_text(url)
        metrics = calculate_metrics(article_text, positive_words, negative_words)
        metrics.update({"URL_ID": url_id, "URL": url})

        output_data.append(metrics)

    output_df = pd.DataFrame(output_data)

    # Ensure the columns are in the same order as in the structure file
    output_columns = structure_df.columns.tolist()
    output_df = output_df[output_columns]

    output_df.to_excel(output_file, index=False)
    print(f"Output saved to {output_file}")

# Main function to run the script
if __name__ == "__main__":
    # Upload the files in Google Colab
    # uploaded = files.upload()

    # Adjust the file paths
    input_file = '/content/Input.xlsx'  # The uploaded input Excel file
    output_file = '/content/output.xlsx'  # The desired output Excel file
    positive_words_file = '/content/positive-words.txt'  # The uploaded positive words file
    negative_words_file = '/content/negative-words.txt'  # The uploaded negative words file
    structure_file = '/content/Output Data Structure.xlsx'  # The uploaded output structure Excel file

    # Process the input file and generate the output
    process_input_file(input_file, output_file, positive_words_file, negative_words_file, structure_file)

    # Download the output file
    files.download(output_file)

